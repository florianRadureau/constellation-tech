"""
Star detection service using OpenCV.

Detects bright stars/points in constellation images generated by Imagen.
"""

import logging
from dataclasses import dataclass
from typing import Tuple

import cv2
import numpy as np
from PIL import Image

logger = logging.getLogger(__name__)


@dataclass
class StarPosition:
    """
    Position and metadata for a detected star.

    Attributes:
        x: X coordinate in pixels
        y: Y coordinate in pixels
        brightness: Average brightness (0-255)
        color: RGB color tuple
        size: Area in pixels
    """

    x: int
    y: int
    brightness: float
    color: Tuple[int, int, int]
    size: int

    def __repr__(self) -> str:
        """String representation for logging."""
        return (
            f"Star(x={self.x}, y={self.y}, brightness={self.brightness:.1f}, "
            f"size={self.size}, color={self.color})"
        )


class StarDetector:
    """
    Detect star positions in constellation images.
    """

    def __init__(
        self,
        min_brightness: int = 180,
        min_size: int = 10,
        max_stars: int = 20,
    ) -> None:
        """
        Initialize star detector with detection parameters.

        Args:
            min_brightness: Minimum brightness threshold (0-255)
            min_size: Minimum star area in pixels
            max_stars: Maximum number of stars to detect
        """
        self.min_brightness = min_brightness
        self.min_size = min_size
        self.max_stars = max_stars

        logger.info(
            f"StarDetector initialized (brightness≥{min_brightness}, "
            f"size≥{min_size}, max={max_stars})"
        )

    def detect(self, image: Image.Image) -> list[StarPosition]:
        """
        Detect stars in constellation image.

        Algorithm (MVP approach):
        1. Convert to grayscale
        2. Apply brightness threshold
        3. Find contours (connected components)
        4. Filter by size
        5. Calculate center of mass for each blob
        6. Extract dominant color at center
        7. Sort by brightness (descending)

        Args:
            image: PIL Image (RGBA or RGB)

        Returns:
            List of StarPosition objects, sorted by brightness (brightest first)

        Example:
            >>> stars = detector.detect(image)
            >>> brightest = stars[0]  # Brightest star
            >>> print(f"Position: ({brightest.x}, {brightest.y})")
        """
        logger.info(f"Detecting stars in {image.size} image...")

        # Convert PIL to OpenCV format
        cv_image = self._pil_to_cv(image)

        # Convert to grayscale for detection
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

        # Apply brightness threshold
        _, thresh = cv2.threshold(
            gray, self.min_brightness, 255, cv2.THRESH_BINARY
        )

        # Find contours
        contours, _ = cv2.findContours(
            thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )

        logger.debug(f"Found {len(contours)} potential stars")

        # Process contours into stars
        stars: list[StarPosition] = []

        for contour in contours:
            # Calculate area
            area = cv2.contourArea(contour)

            if area < self.min_size:
                continue  # Too small

            # Calculate moments for center of mass
            M = cv2.moments(contour)

            if M["m00"] == 0:
                continue  # Invalid contour

            # Center coordinates
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])

            # Get brightness at center
            brightness = float(gray[cy, cx])

            # Get color at center (from original image)
            color = self._get_color_at_point(cv_image, cx, cy)

            # Create StarPosition
            star = StarPosition(
                x=cx, y=cy, brightness=brightness, color=color, size=int(area)
            )

            stars.append(star)

        # Sort by brightness (descending)
        stars.sort(key=lambda s: s.brightness, reverse=True)

        # Limit to max_stars
        stars = stars[: self.max_stars]

        logger.info(f"Detected {len(stars)} stars (after filtering)")

        # Log top 3 for debugging
        for i, star in enumerate(stars[:3]):
            logger.debug(f"  Star {i+1}: {star}")

        return stars

    def _pil_to_cv(self, image: Image.Image) -> np.ndarray:
        """
        Convert PIL Image to OpenCV format.

        Args:
            image: PIL Image

        Returns:
            OpenCV image (numpy array in BGR format)
        """
        # Convert to RGB if needed
        if image.mode == "RGBA":
            image = image.convert("RGB")
        elif image.mode != "RGB":
            image = image.convert("RGB")

        # Convert to numpy array
        np_image = np.array(image)

        # Convert RGB to BGR (OpenCV format)
        cv_image = cv2.cvtColor(np_image, cv2.COLOR_RGB2BGR)

        return cv_image

    def _get_color_at_point(
        self, cv_image: np.ndarray, x: int, y: int, radius: int = 5
    ) -> Tuple[int, int, int]:
        """
        Get dominant color at a point (with small radius for averaging).

        Args:
            cv_image: OpenCV image (BGR)
            x: X coordinate
            y: Y coordinate
            radius: Radius for color sampling

        Returns:
            RGB color tuple (averaged over radius)
        """
        height, width = cv_image.shape[:2]

        # Ensure coordinates are in bounds
        x = max(0, min(x, width - 1))
        y = max(0, min(y, height - 1))

        # Sample area around point
        x1 = max(0, x - radius)
        x2 = min(width, x + radius + 1)
        y1 = max(0, y - radius)
        y2 = min(height, y + radius + 1)

        region = cv_image[y1:y2, x1:x2]

        # Average color in BGR
        avg_bgr = region.mean(axis=(0, 1))

        # Convert BGR to RGB
        b, g, r = avg_bgr
        return (int(r), int(g), int(b))

    def _estimate_star_size(
        self, gray: np.ndarray, x: int, y: int, radius: int = 25
    ) -> int:
        """
        Estimate star size by counting bright pixels around center.

        Args:
            gray: Grayscale image (numpy array)
            x, y: Star center coordinates
            radius: Search radius in pixels

        Returns:
            Approximate size in pixels (number of bright pixels)
        """
        # Extract region around star
        height, width = gray.shape
        x1 = max(0, x - radius)
        y1 = max(0, y - radius)
        x2 = min(width, x + radius)
        y2 = min(height, y + radius)

        region = gray[y1:y2, x1:x2]

        if region.size == 0:
            return 0

        # Count pixels above 80% of star brightness
        star_brightness = gray[y, x]
        threshold = star_brightness * 0.8
        bright_pixels = int(np.sum(region >= threshold))

        return bright_pixels

    def detect_constellation_lines(self, image: Image.Image) -> list[dict]:
        """
        Detect constellation lines only (pure line detection).

        Uses Canny edge detection + HoughLinesP to find straight lines
        in the constellation, regardless of color.

        Args:
            image: PIL Image from Imagen

        Returns:
            List of line dicts: [{"x1": int, "y1": int, "x2": int, "y2": int, "length": float}, ...]

        Example:
            >>> lines = detector.detect_constellation_lines(image)
            >>> print(f"Found {len(lines)} lines")
        """
        import math

        logger.info("Detecting constellation lines (pure geometric detection)...")

        # Convert PIL to OpenCV
        cv_image = self._pil_to_cv(image)
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

        # Gaussian blur to reduce noise
        blur = cv2.GaussianBlur(gray, (5, 5), 0)

        # Canny edge detection
        edges = cv2.Canny(blur, threshold1=30, threshold2=100, apertureSize=3)

        # HoughLinesP for straight line detection
        lines = cv2.HoughLinesP(
            edges,
            rho=1,  # Distance resolution in pixels
            theta=np.pi / 180,  # Angle resolution in radians
            threshold=80,  # Minimum number of points to form a line
            minLineLength=50,  # Minimum line length
            maxLineGap=15,  # Maximum gap between segments
        )

        detected_lines = []

        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                length = math.hypot(x2 - x1, y2 - y1)

                detected_lines.append({
                    "x1": x1,
                    "y1": y1,
                    "x2": x2,
                    "y2": y2,
                    "length": length,
                })

            logger.info(f"✓ Detected {len(detected_lines)} constellation lines")
        else:
            logger.warning("No lines detected in image")

        return detected_lines

    def visualize_lines(
        self, image: Image.Image, lines: list[dict], output_path: str
    ) -> None:
        """
        Create debug image with detected lines and endpoints.

        Args:
            image: Original PIL Image
            lines: List of line dicts from detect_constellation_lines()
            output_path: Path to save visualization

        Example:
            >>> detector.visualize_lines(image, lines, "debug_lines.png")
        """
        logger.info(f"Creating line visualization with {len(lines)} lines...")

        # Convert to OpenCV
        cv_image = self._pil_to_cv(image)

        # Draw lines in green
        for line in lines:
            cv2.line(
                cv_image,
                (line["x1"], line["y1"]),
                (line["x2"], line["y2"]),
                (0, 255, 0),  # Green
                2,
            )

            # Mark endpoints with red circles
            cv2.circle(cv_image, (line["x1"], line["y1"]), 5, (0, 0, 255), -1)
            cv2.circle(cv_image, (line["x2"], line["y2"]), 5, (0, 0, 255), -1)

        # Save
        cv_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
        result = Image.fromarray(cv_rgb)
        result.save(output_path)

        logger.info(f"✓ Saved line visualization to {output_path}")

    def _analyze_line_network(self, lines: list[dict]) -> list[dict]:
        """
        Analyze line network to find nodes (clusters of endpoints).

        A node is a spatial cluster of endpoints, representing a junction
        or connection point in the constellation.

        Args:
            lines: List of line dicts from detect_constellation_lines()

        Returns:
            List of node dicts: [{"x": int, "y": int, "degree": int}, ...]
            where degree = number of lines connected to this node.
            Sorted by degree (descending) - most connected nodes first.

        Example:
            >>> nodes = detector._analyze_line_network(lines)
            >>> print(f"Found {len(nodes)} nodes")
        """
        import math

        logger.debug("Analyzing line network to find nodes...")

        # Extract all endpoints
        endpoints = []
        for line in lines:
            endpoints.append((line["x1"], line["y1"]))
            endpoints.append((line["x2"], line["y2"]))

        logger.debug(f"Extracted {len(endpoints)} endpoints from {len(lines)} lines")

        # Spatial clustering (40px distance) to find nodes
        nodes = []
        used = set()

        for i, (x, y) in enumerate(endpoints):
            if i in used:
                continue

            # Find all endpoints within 40px (same node)
            cluster = [(x, y)]
            for j, (ox, oy) in enumerate(endpoints):
                if j <= i or j in used:
                    continue

                distance = math.hypot(x - ox, y - oy)
                if distance < 40:
                    cluster.append((ox, oy))
                    used.add(j)

            # Average position of cluster = node position
            avg_x = int(np.mean([p[0] for p in cluster]))
            avg_y = int(np.mean([p[1] for p in cluster]))
            degree = len(cluster)  # Number of connections

            nodes.append({"x": avg_x, "y": avg_y, "degree": degree})

        # Sort by degree (most connected nodes first)
        nodes.sort(key=lambda n: n["degree"], reverse=True)

        logger.info(f"✓ Found {len(nodes)} nodes in line network")
        logger.debug(
            f"  Top 3 nodes: {[(n['degree'], n['x'], n['y']) for n in nodes[:3]]}"
        )

        return nodes

    def _position_labels_from_nodes(
        self,
        nodes: list[dict],
        cv_image: np.ndarray,
        gray: np.ndarray,
        tech_count: int,
    ) -> list[StarPosition]:
        """
        Position labels at important nodes in the network.

        Selects the N most connected nodes and creates StarPosition objects
        at those locations.

        Args:
            nodes: List of node dicts from _analyze_line_network()
            cv_image: OpenCV image (for color extraction)
            gray: Grayscale image (for brightness)
            tech_count: Number of labels to position

        Returns:
            List of StarPosition objects at node locations

        Example:
            >>> stars = detector._position_labels_from_nodes(nodes, cv_image, gray, 7)
        """
        logger.debug(f"Positioning {tech_count} labels at important nodes...")

        stars: list[StarPosition] = []

        # Select top N most connected nodes
        selected_nodes = nodes[:tech_count]

        for node in selected_nodes:
            x, y = node["x"], node["y"]

            # Calculate metadata at this position
            brightness = float(gray[y, x])
            color = self._get_color_at_point(cv_image, x, y)
            size = self._estimate_star_size(gray, x, y)

            stars.append(
                StarPosition(
                    x=x, y=y, brightness=brightness, color=color, size=size
                )
            )

        # Sort by brightness (brightest first) for consistency with other methods
        stars.sort(key=lambda s: s.brightness, reverse=True)

        logger.info(f"✓ Positioned {len(stars)} labels at network nodes")

        return stars

    def detect_from_constellation_lines(
        self, image: Image.Image, target_count: int = None
    ) -> list[StarPosition]:
        """
        Detect constellation stars by analyzing line network.

        New approach (v2):
        1. Detect all constellation lines (pure geometric detection)
        2. Create debug visualization (lines + endpoints)
        3. Analyze line network to find nodes (junctions/endpoints)
        4. Position labels at important nodes (most connected)

        This is more robust because it uses the topological structure
        of the constellation rather than trying to find individual stars.

        Args:
            image: PIL Image from Imagen
            target_count: Optional number of stars to detect (defaults to all nodes)

        Returns:
            List of StarPosition objects at network nodes

        Example:
            >>> stars = detector.detect_from_constellation_lines(image, target_count=7)
            >>> print(f"Found {len(stars)} stars at network nodes")
        """
        logger.info("Detecting constellation via line network analysis (v2)...")

        # Step 1: Detect constellation lines
        lines = self.detect_constellation_lines(image)

        if not lines:
            logger.warning("No lines detected, falling back to brightness detection")
            return self.detect(image)

        # Step 2: Create debug visualization
        self.visualize_lines(image, lines, "debug_lines.png")

        # Step 3: Analyze line network to find nodes
        nodes = self._analyze_line_network(lines)

        if not nodes:
            logger.warning("No nodes found in network, falling back to brightness detection")
            return self.detect(image)

        # Step 4: Position labels at nodes
        # Convert image for metadata extraction
        cv_image = self._pil_to_cv(image)
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

        # Use target_count or all nodes
        count = target_count if target_count is not None else len(nodes)
        stars = self._position_labels_from_nodes(nodes, cv_image, gray, count)

        return stars

    def detect_with_adjustable_threshold(
        self, image: Image.Image, target_count: int
    ) -> list[StarPosition]:
        """
        Detect stars with automatic method selection.

        Primary method: Line-based detection (analyzes constellation lines)
        Fallback method: Brightness thresholding with adjustment

        The line-based method is more robust because it uses the actual
        constellation structure from Imagen (the connection lines), which
        identifies exactly which stars are part of the constellation.

        Args:
            image: PIL Image
            target_count: Desired number of stars

        Returns:
            List of StarPosition objects

        Example:
            >>> stars = detector.detect_with_adjustable_threshold(image, target_count=10)
        """
        logger.info(f"Detecting {target_count} stars...")

        # Try line-based detection first (more robust)
        logger.info("Attempting line-based constellation detection...")
        stars = self.detect_from_constellation_lines(image)

        # If we got a reasonable number of stars, use them
        if len(stars) >= target_count - 2:  # Allow -2 tolerance
            logger.info(
                f"✓ Line-based detection successful: {len(stars)} stars "
                f"(target was {target_count})"
            )
            # Don't limit to target_count - use all detected constellation stars
            return stars

        # Fallback to brightness-based detection
        logger.warning(
            f"Line-based detection found only {len(stars)} stars, "
            f"falling back to brightness detection"
        )

        # Try initial brightness detection
        stars = self.detect(image)

        if len(stars) >= target_count:
            logger.info(f"Found {len(stars)} stars (target: {target_count})")
            return stars[:target_count]

        # Try lowering threshold
        original_brightness = self.min_brightness
        thresholds = [original_brightness - 20, original_brightness - 40]

        for threshold in thresholds:
            if threshold < 100:  # Don't go too low
                break

            logger.debug(f"Trying lower threshold: {threshold}")
            self.min_brightness = threshold
            stars = self.detect(image)

            if len(stars) >= target_count:
                logger.info(
                    f"Found {len(stars)} stars with threshold={threshold}"
                )
                self.min_brightness = original_brightness  # Restore
                return stars[:target_count]

        # Restore original threshold
        self.min_brightness = original_brightness

        logger.warning(
            f"Could only detect {len(stars)} stars (target: {target_count})"
        )
        return stars

    def visualize_detection(
        self, image: Image.Image, stars: list[StarPosition], output_path: str
    ) -> None:
        """
        Visualize detected stars on image (for debugging).

        Args:
            image: Original PIL Image
            stars: List of detected stars
            output_path: Path to save visualization

        Example:
            >>> detector.visualize_detection(image, stars, "debug_stars.png")
        """
        # Convert to OpenCV
        cv_image = self._pil_to_cv(image)

        # Draw circles on each star
        for i, star in enumerate(stars):
            color = (0, 255, 0)  # Green
            cv2.circle(cv_image, (star.x, star.y), 10, color, 2)

            # Add index label
            cv2.putText(
                cv_image,
                str(i + 1),
                (star.x + 15, star.y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                color,
                1,
            )

        # Convert back to PIL and save
        cv_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
        result_image = Image.fromarray(cv_rgb)
        result_image.save(output_path)

        logger.info(f"Saved visualization to {output_path}")
